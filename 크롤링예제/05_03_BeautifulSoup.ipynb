{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3.2 beautifulsoup 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install beautifulsoup4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3.3 기본 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html lang=\"en\">\\n\\n<head>\\n\\n  <meta charset=\"utf-8\">\\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\\n  <meta name=\"description\" content=\"\">\\n  <meta name=\"author\" content=\"\">\\n\\n  <title>Clean Blog - 곰돌이 Theme</title>\\n\\n  <!-- Bootstrap core CSS -->\\n  <link href=\"vendor/bootstrap/css/bootstrap.min.css\" rel=\"stylesheet\">\\n\\n  <!-- Custom fonts for this template -->\\n  <link href=\"vendor/fontawesome-free/css/all.min.css\" rel=\"stylesheet\" type=\"text/css\">\\n  <link href=\\'https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic\\' rel=\\'stylesheet\\' type=\\'text/css\\'>\\n  <link href=\\'https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800\\' rel=\\'stylesheet\\' type=\\'text/css\\'>\\n\\n  <!-- Custom styles for this template -->\\n  <link href=\"css/clean-blog.min.css\" rel=\"stylesheet\">\\n\\n</head>\\n\\n<body>\\n\\n  <!-- Navigation -->\\n  <nav class=\"navbar navbar-expand-lg navbar-light fixed-top\" id=\"mainNav\">\\n    <div class=\"container\">\\n      <a class=\"navbar-brand\" href=\"index.html\">Home</a>     \\n    </div>\\n  </nav>\\n\\n  <!-- Page Header -->\\n  <header class=\"masthead\" style=\"background-image: url(\\'img/home-bg.jpg\\')\">\\n    <div class=\"overlay\"></div>\\n    <div class=\"container\">\\n      <div class=\"row\">\\n        <div class=\"col-lg-8 col-md-10 mx-auto\">\\n          <div class=\"site-heading\">\\n            <h1>곰돌이 블로그</h1>\\n            <span class=\"subheading\">곰돌이 블로그에 오신 것을 환영합니다.</span>\\n          </div>\\n        </div>\\n      </div>\\n    </div>\\n  </header>\\n\\n  <!-- Main Content -->\\n  <div class=\"container\">\\n    <div class=\"row\">\\n      <div class=\"col-lg-8 col-md-10 mx-auto\">\\n        <div class=\"post-preview\">\\n          <a href=\"index.html\">\\n            <h2 class=\"post-title\">\\n              단풍구경가자~~\\n            </h2>\\n            <h3 class=\"post-subtitle\">\\n              동키랑 단풍구경 다녀왔어요\\n            </h3>\\n          </a>\\n          <p class=\"post-meta\">September 24, 2021</p>\\n        </div>\\n        <hr>\\n        <div class=\"post-preview\">\\n          <a href=\"index.html\">\\n            <h2 class=\"post-title\">\\n              다이어트 시작!\\n            </h2>\\n            <h3 class=\"post-subtitle\">\\n              꿀은 이제 그만, 날씬한 곰돌이로 다시 태어나기\\n            </h3>          \\n          </a>\\n          <p class=\"post-meta\">June 18, 2021</p>\\n        </div>\\n        <hr>\\n        <div class=\"post-preview\">\\n          <a href=\"index.html\">\\n            <h2 class=\"post-title\">\\n              꽃놀이간다!\\n            </h2>\\n            <h3 class=\"post-subtitle\">\\n              화창한 봄날, 티거랑 함께 산책간 이야기\\n            </h3>\\n          </a>\\n          <p class=\"post-meta\">March 24, 2021</p>\\n        </div>\\n        <hr>\\n        <div class=\"post-preview\">\\n          <a href=\"index.html\">\\n            <h2 class=\"post-title\">\\n              내 꿀은 누가 다 먹었나?\\n            </h2>\\n            <h3 class=\"post-subtitle\">\\n              없어진 꿀의 행방을 찾아라\\n            </h3>\\n          </a>\\n          <p class=\"post-meta\">July 8, 2020</p>\\n        </div>\\n        <hr>\\n        <!-- Pager -->\\n        <div class=\"clearfix\">\\n          <a class=\"btn btn-primary float-right\" href=\"#\">Older Posts &rarr;</a>\\n        </div>\\n      </div>\\n    </div>\\n  </div>\\n\\n  <hr>\\n\\n  <!-- Footer -->\\n  <footer>\\n    <div class=\"container\">\\n      <div class=\"row\">\\n        <div class=\"col-lg-8 col-md-10 mx-auto\">\\n          <p class=\"copyright text-muted\">Copyright &copy; My Website 2021</p>\\n        </div>\\n      </div>\\n    </div>\\n  </footer>\\n</body>\\n\\n</html>\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filename = \"index.html\" # 경로문제 겪지 않으려면 풀경로 확인해서 넣어줘도 됨\n",
    "filename = r\"C:\\Users\\USER\\Documents\\GitHub\\Web-Crawling\\크롤링예제\\index.html\"\n",
    "html = \"\"\n",
    "\n",
    "with open (filename, 'r', encoding='UTF-8') as file:  \n",
    "    for line in file:               \n",
    "        html += line\n",
    "        \n",
    "# with open (filename, 'r', encoding='UTF-8') as file:\n",
    "#     html = file.read()\n",
    "\n",
    "html    # print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"width=device-width, initial-scale=1, shrink-to-fit=no\" name=\"viewport\"/>\n",
       "<meta content=\"\" name=\"description\"/>\n",
       "<meta content=\"\" name=\"author\"/>\n",
       "<title>Clean Blog - 곰돌이 Theme</title>\n",
       "<!-- Bootstrap core CSS -->\n",
       "<link href=\"vendor/bootstrap/css/bootstrap.min.css\" rel=\"stylesheet\"/>\n",
       "<!-- Custom fonts for this template -->\n",
       "<link href=\"vendor/fontawesome-free/css/all.min.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<!-- Custom styles for this template -->\n",
       "<link href=\"css/clean-blog.min.css\" rel=\"stylesheet\"/>\n",
       "</head>\n",
       "<body>\n",
       "<!-- Navigation -->\n",
       "<nav class=\"navbar navbar-expand-lg navbar-light fixed-top\" id=\"mainNav\">\n",
       "<div class=\"container\">\n",
       "<a class=\"navbar-brand\" href=\"index.html\">Home</a>\n",
       "</div>\n",
       "</nav>\n",
       "<!-- Page Header -->\n",
       "<header class=\"masthead\" style=\"background-image: url('img/home-bg.jpg')\">\n",
       "<div class=\"overlay\"></div>\n",
       "<div class=\"container\">\n",
       "<div class=\"row\">\n",
       "<div class=\"col-lg-8 col-md-10 mx-auto\">\n",
       "<div class=\"site-heading\">\n",
       "<h1>곰돌이 블로그</h1>\n",
       "<span class=\"subheading\">곰돌이 블로그에 오신 것을 환영합니다.</span>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</header>\n",
       "<!-- Main Content -->\n",
       "<div class=\"container\">\n",
       "<div class=\"row\">\n",
       "<div class=\"col-lg-8 col-md-10 mx-auto\">\n",
       "<div class=\"post-preview\">\n",
       "<a href=\"index.html\">\n",
       "<h2 class=\"post-title\">\n",
       "              단풍구경가자~~\n",
       "            </h2>\n",
       "<h3 class=\"post-subtitle\">\n",
       "              동키랑 단풍구경 다녀왔어요\n",
       "            </h3>\n",
       "</a>\n",
       "<p class=\"post-meta\">September 24, 2021</p>\n",
       "</div>\n",
       "<hr/>\n",
       "<div class=\"post-preview\">\n",
       "<a href=\"index.html\">\n",
       "<h2 class=\"post-title\">\n",
       "              다이어트 시작!\n",
       "            </h2>\n",
       "<h3 class=\"post-subtitle\">\n",
       "              꿀은 이제 그만, 날씬한 곰돌이로 다시 태어나기\n",
       "            </h3>\n",
       "</a>\n",
       "<p class=\"post-meta\">June 18, 2021</p>\n",
       "</div>\n",
       "<hr/>\n",
       "<div class=\"post-preview\">\n",
       "<a href=\"index.html\">\n",
       "<h2 class=\"post-title\">\n",
       "              꽃놀이간다!\n",
       "            </h2>\n",
       "<h3 class=\"post-subtitle\">\n",
       "              화창한 봄날, 티거랑 함께 산책간 이야기\n",
       "            </h3>\n",
       "</a>\n",
       "<p class=\"post-meta\">March 24, 2021</p>\n",
       "</div>\n",
       "<hr/>\n",
       "<div class=\"post-preview\">\n",
       "<a href=\"index.html\">\n",
       "<h2 class=\"post-title\">\n",
       "              내 꿀은 누가 다 먹었나?\n",
       "            </h2>\n",
       "<h3 class=\"post-subtitle\">\n",
       "              없어진 꿀의 행방을 찾아라\n",
       "            </h3>\n",
       "</a>\n",
       "<p class=\"post-meta\">July 8, 2020</p>\n",
       "</div>\n",
       "<hr/>\n",
       "<!-- Pager -->\n",
       "<div class=\"clearfix\">\n",
       "<a class=\"btn btn-primary float-right\" href=\"#\">Older Posts →</a>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<hr/>\n",
       "<!-- Footer -->\n",
       "<footer>\n",
       "<div class=\"container\">\n",
       "<div class=\"row\">\n",
       "<div class=\"col-lg-8 col-md-10 mx-auto\">\n",
       "<p class=\"copyright text-muted\">Copyright © My Website 2021</p>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</footer>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# 가져온 HTML 문서를 lxml parser를 통해서 Bs 객체로 만들어 줌\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "soup\n",
    "\n",
    "# soup은 해당 url의 모든 HTML 정보를 가진 객체\n",
    "# lxml은 String형식의 HTML문서를 살아있는 HTML문서, 의미있는 문서로 만들어주는 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2 class=\"post-title\">\n",
       "              단풍구경가자~~\n",
       "            </h2>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2') # 찾은 결과 중 첫번째 요소 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h2 class=\"post-title\">\n",
       "               단풍구경가자~~\n",
       "             </h2>,\n",
       " <h2 class=\"post-title\">\n",
       "               다이어트 시작!\n",
       "             </h2>,\n",
       " <h2 class=\"post-title\">\n",
       "               꽃놀이간다!\n",
       "             </h2>,\n",
       " <h2 class=\"post-title\">\n",
       "               내 꿀은 누가 다 먹었나?\n",
       "             </h2>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('h2') # 찾은 결과 요소 모두 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n              단풍구경가자~~\\n            '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2').text    # 불필요한 코드 빼고 문자열만 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'단풍구경가자~~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2').text.strip()    # 문자열 양쪽 공백 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단풍구경가자~~\n",
      "다이어트 시작!\n",
      "꽃놀이간다!\n",
      "내 꿀은 누가 다 먹었나?\n"
     ]
    }
   ],
   "source": [
    "title_list = soup.find_all('h2')\n",
    "정리된title = []\n",
    "for title in title_list:\n",
    "    print(title.text.strip())\n",
    "    정리된title.append(title.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "September 24, 2021\n",
      "June 18, 2021\n",
      "March 24, 2021\n",
      "July 8, 2020\n",
      "Copyright © My Website 2021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['September 24, 2021', 'June 18, 2021', 'March 24, 2021', 'July 8, 2020']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_list = soup.find_all('p')\n",
    "정리된date = []\n",
    "for date in date_list:\n",
    "    print(date.text.strip())\n",
    "    정리된date.append(date.text.strip())\n",
    "정리된date.pop()    # 날짜 데이터가 아닌 마지막 요소 제거 (Copyright...)\n",
    "정리된date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"post-meta\">September 24, 2021</p>,\n",
       " <p class=\"post-meta\">June 18, 2021</p>,\n",
       " <p class=\"post-meta\">March 24, 2021</p>,\n",
       " <p class=\"post-meta\">July 8, 2020</p>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_list = soup.find_all('p', {'class': 'post-meta'})\n",
    "date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "September 24, 2021\n",
      "June 18, 2021\n",
      "March 24, 2021\n",
      "July 8, 2020\n"
     ]
    }
   ],
   "source": [
    "for date in date_list:\n",
    "    print(date.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>단풍구경가자~~</td>\n",
       "      <td>동키랑 단풍구경 다녀왔어요</td>\n",
       "      <td>September 24, 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>다이어트 시작!</td>\n",
       "      <td>꿀은 이제 그만, 날씬한 곰돌이로 다시 태어나기</td>\n",
       "      <td>June 18, 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>꽃놀이간다!</td>\n",
       "      <td>화창한 봄날, 티거랑 함께 산책간 이야기</td>\n",
       "      <td>March 24, 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>내 꿀은 누가 다 먹었나?</td>\n",
       "      <td>없어진 꿀의 행방을 찾아라</td>\n",
       "      <td>July 8, 2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title                    subtitle                date\n",
       "0        단풍구경가자~~              동키랑 단풍구경 다녀왔어요  September 24, 2021\n",
       "1        다이어트 시작!  꿀은 이제 그만, 날씬한 곰돌이로 다시 태어나기       June 18, 2021\n",
       "2          꽃놀이간다!      화창한 봄날, 티거랑 함께 산책간 이야기      March 24, 2021\n",
       "3  내 꿀은 누가 다 먹었나?              없어진 꿀의 행방을 찾아라        July 8, 2020"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "title_list = []\n",
    "subtitle_list = []\n",
    "date_list = []\n",
    "\n",
    "#1. 포스트 리스트\n",
    "post_list = soup.find_all('div', {'class': 'post-preview'})\n",
    "\n",
    "#2. 제목, 소제목, 날짜 리스트\n",
    "for post in post_list:\n",
    "    title = post.find('h2', {'class' : 'post-title'}).text.strip()\n",
    "    subtitle = post.find('h3', {'class' : 'post-subtitle'}).text.strip()\n",
    "    date = post.find('p', {'class' : 'post-meta'}).text.strip()\n",
    "    title_list.append(title)\n",
    "    subtitle_list.append(subtitle)\n",
    "    date_list.append(date)\n",
    "    \n",
    "# #3. 데이터프레임 만들기\n",
    "dfzip = zip(title_list, subtitle_list, date_list)\n",
    "df = pd.DataFrame(\n",
    "    dfzip, columns=[\"title\", \"subtitle\", \"date\"]\n",
    ")\n",
    "# df = pd.DataFrame({'title': title_list, 'subtitle': subtitle_list, 'date': date_list})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일로 저장하는 방법 (csv, excel)\n",
    "df.to_csv(r\"C:\\Users\\USER\\Documents\\GitHub\\Web-Crawling\\크롤링예제\\결과.csv\", encoding='utf', sep=\" \")\n",
    "df.to_excel(r\"C:\\Users\\USER\\Documents\\GitHub\\Web-Crawling\\크롤링예제\\결과.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB부분처리안됨\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "# DB에 저장하는 방법\n",
    "from sqlalchemy import engine, create_engine, DateTime, Column, Integer, String, Enum\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.sql import func\n",
    "import sqlalchemy\n",
    "\n",
    "Base = sqlalchemy.orm.declarative_base()\n",
    "\n",
    "class Tausers(Base):\n",
    "    __tablename__ = \"tauser\"\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    username = Column(String)\n",
    "    email =  Column(String)\n",
    "    created_at = Column(DateTime(timezone=True), server_default=func.now())\n",
    "    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n",
    "\n",
    "    Base = sqlalchemy.orm.declarative_base()\n",
    "\n",
    "\n",
    "class MySQLDatabase:\n",
    "    def __init__(self, db_url):\n",
    "        self.engine = create_engine(db_url)\n",
    "        self.Session = sessionmaker(bind=self.engine)\n",
    "        # Base.metadata.create_all(self.engine)\n",
    "\n",
    "    def add_user(self, username, email):\n",
    "        session = self.Session()\n",
    "        user = Tausers(username=username, email=email)\n",
    "        session.add(user)\n",
    "        session.commit()\n",
    "        session.close()\n",
    "\n",
    "    def get_user_by_username(self, username):\n",
    "        session = self.Session()\n",
    "        user = session.query(Tausers).filter_by(username=username).first()\n",
    "        session.close()\n",
    "        return user\n",
    "\n",
    "    def get_user_by_email(self, email):\n",
    "        session = self.Session()\n",
    "        user = session.query(Tausers).filter_by(email=email).first()\n",
    "        session.close()\n",
    "        return user\n",
    "\n",
    "    def update_user_email(self, username, new_email):\n",
    "        session = self.Session()\n",
    "        user = session.query(Tausers).filter_by(username=username).first()\n",
    "        if user:\n",
    "            user.email = new_email\n",
    "            session.commit()\n",
    "        session.close()\n",
    "\n",
    "    def delete_user(self, username):\n",
    "        session = self.Session()\n",
    "        user = session.query(Tausers).filter_by(username=username).first()\n",
    "        if user:\n",
    "            session.delete(user)\n",
    "            session.commit()\n",
    "        session.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        user = \"root\" # root\n",
    "        password = \"\"\n",
    "        host = \"localhost\"\n",
    "        port = 3306\n",
    "        db = \"test\"\n",
    "\n",
    "        db_url = f\"mysql+pymysql://{user}:{password}@{host}:{port}/{db}\"\n",
    "        db = MySQLDatabase(db_url)\n",
    "\n",
    "        print(db.__repr__)  # 변수 = eval(\"변수\") => 보안적으로 문제 있어 권장되지 않음\n",
    "\n",
    "        db.add_user(\"john_doe\", \"john@example.com\")\n",
    "        user =  db.get_user_by_username(\"john_doe\")\n",
    "        print(user.username, user.email)\n",
    "        # db.update_user_email(\"john_doe\", \"new_email@example.com\")\n",
    "        # user =  db.get_user_by_username(\"john_doe\")\n",
    "        # print(user.username, user.email)\n",
    "\n",
    "        # db.delete_user(\"john_doe\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"DB부분처리안됨\")    \n",
    "        print(\"e\")\n",
    "\n",
    "\n",
    "# 디비명 test\n",
    "\n",
    "# CREATE TABLE `tauser` (\n",
    "#   `id` INT(10) NOT NULL AUTO_INCREMENT,\n",
    "#   `username` VARCHAR(50) NOT NULL DEFAULT '0' COLLATE 'utf8mb4_general_ci',\n",
    "#   `email` VARCHAR(50) NOT NULL DEFAULT '0' COLLATE 'utf8mb4_general_ci',\n",
    "#   `created_at` TIMESTAMP NULL DEFAULT NULL,\n",
    "#   `updated_at` TIMESTAMP NULL DEFAULT NULL,\n",
    "#   PRIMARY KEY (`id`) USING BTREE\n",
    "# )\n",
    "# COLLATE='utf8mb4_general_ci'\n",
    "# ENGINE=InnoDB\n",
    "# AUTO_INCREMENT=5\n",
    "# ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "<div class=\"alert alert-warning\">\n",
    "[Tip] CSS Selector 를 활용한 태그 선택\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# css 문법\n",
    "# select_all & select_one\n",
    "\n",
    "soup.select('a > h2')   # soup.select('a h2') 로 작성해도 동일하게 동작함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('a h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('body > div > div > div > div:nth-child(1) > a > h2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3.4 실습-쇼핑몰 가격 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    [문제]  \n",
    "    \n",
    "    \n",
    "상품정보가 포함된 하나의 페이지를 파싱하여 상품정보가 포함된 데이터 프레임을 생성하세요.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# http://www.neweracapkorea.com/shop/shopbrand.html?xcode=031&mcode=002&type=Y&gf_ref=Yz1vU0FlS3M=\n",
    "base_url = \"http://www.neweracapkorea.com\"\n",
    "cap_total_url = \"/shop/shopbrand.html?xcode=031&mcode=002&type=Y&gf_ref=Yz1vU0FlS3M=\"\n",
    "base_url + cap_total_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get html\n",
    "response = requests.get(base_url+cap_total_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup을 활용하여 데이터 파싱\n",
    "soup = BeautifulSoup(response.content, \"lxml\")\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_info = soup.findAll('div', {'class':'tb-center'})\n",
    "cap_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url \n",
    "cap_url = cap_info[0].find('a').get('href')\n",
    "print(cap_url)\n",
    "\n",
    "#상품명 \n",
    "name = cap_info[0].find('li', {'class':'dsc'}).text\n",
    "print(name)\n",
    "\n",
    "#가격 \n",
    "price = cap_info[0].find('li', {'class':'price'}).text\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name_list = []\n",
    "price_list = []\n",
    "url_list = []\n",
    "\n",
    "for cap in cap_info:\n",
    "    name = cap.find('li', {'class':'dsc'}).text\n",
    "    price = cap.find('li', {'class':'price'}).text\n",
    "    url = cap.find('a').get('href')\n",
    "    print(\"이름: {}, 가격: {}\".format(name, price))\n",
    "    name_list.append(name)\n",
    "    price_list.append(price)\n",
    "    url_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"이름\": name_list, \"가격\" : price_list, \"url\": url_list})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    [문제]  \n",
    "    \n",
    "    \n",
    "앞의 데이터프레임에 저장한 상품 상세페이지의 URL을 참조하여, 각각의 상품정보의 상세정보를 \n",
    "포함하는 데이터 프레임을 생성하세요.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get html\n",
    "response = requests.get(base_url + df['url'][0])\n",
    "\n",
    "# BeautifulSoup을 활용하여 데이터 파싱\n",
    "soup = BeautifulSoup(response.content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_name = soup.find('h3', {'class':'tit-prd'}).text.strip()\n",
    "cap_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_info = soup.find('tbody')\n",
    "features = cap_info.findAll('div', {'class':'tb-left'})\n",
    "\n",
    "for f in features:\n",
    "    print(f.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_list = []\n",
    "for f in features:\n",
    "    fic_list.append(f.text.strip())\n",
    "fic_list\n",
    "\n",
    "cap_dict = {'이름': cap_name}\n",
    "\n",
    "########## 추가부분 시작 ##################\n",
    "if len(fic_list) % 2 != 0:\n",
    "    fic_list = fic_list[1:] \n",
    "########## 추가부분 끝  ##################\n",
    "\n",
    "for i in range(len(fic_list)):\n",
    "    if i % 2 == 0:\n",
    "        cap_dict.update({fic_list[i]: fic_list[i+1]})\n",
    "\n",
    "cap_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_df = pd.DataFrame(data = cap_dict,  index = [0])\n",
    "cap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_detail_df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    print(i , end='... ')\n",
    "    # (1)df에 저장된 url 읽어오기\n",
    "    url = df['url'][i]\n",
    "    response = requests.get(base_url + url)\n",
    "    soup = BeautifulSoup(response.content, \"lxml\")\n",
    "    \n",
    "    # (2)상세페이지의 정보 파싱\n",
    "    cap_name = soup.find('h3', {'class':'tit-prd'}).text.strip()\n",
    "    cap_info = soup.find('tbody')\n",
    "    features = cap_info.findAll('div', {'class':'tb-left'})\n",
    "    \n",
    "    fic_list = []\n",
    "    for f in features:\n",
    "        fic_list.append(f.text.strip())\n",
    "    \n",
    "    # (3)파싱한 정보를 사용하여 딕셔너리 생성\n",
    "    cap_dict = {'제품명': cap_name}\n",
    "\n",
    "    ########## 추가부분 시작 ##################\n",
    "    if len(fic_list) % 2 != 0:\n",
    "        fic_list = fic_list[1:] \n",
    "    ########## 추가부분 끝  ##################\n",
    "\n",
    "    for i in range(len(fic_list)):\n",
    "        if i % 2 == 0:\n",
    "            if fic_list[i] != '':\n",
    "                cap_dict.update({fic_list[i]: fic_list[i+1]})\n",
    "    \n",
    "    # (4)생성한 딕셔너리로 데이터프레임 생성\n",
    "    temp_df = pd.DataFrame(data = cap_dict,  index = [0])\n",
    "\n",
    "    # (5) 데이터프레임 추가\n",
    "    if len(cap_detail_df) == 0:\n",
    "        cap_detail_df = temp_df\n",
    "    else:\n",
    "        cap_detail_df = cap_detail_df.append(temp_df, ignore_index = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_detail_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_detail_df['특이사항'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    [문제]  \n",
    "    \n",
    "    \n",
    "여러 페이지의 정보를 앞의 데이터프레임에 저장한 상품 상세페이지의 URL을 참조하여, 각각의 \n",
    "상품정보의 상세정보를 포함하는 데이터 프레임을 생성하세요.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://www.neweracapkorea.com\"\n",
    "\n",
    "name_list = []\n",
    "price_list = []\n",
    "url_list = []\n",
    "index = 1\n",
    "\n",
    "while True: \n",
    "    try :\n",
    "        print('{} 페이지 파싱.....'.format(index))\n",
    "        page_url = f\"/shop/shopbrand.html?type=Y&xcode=031&mcode=002&sort=&page={index}\"\n",
    "        response = requests.get(base_url+page_url)\n",
    "\n",
    "        # BeautifulSoup을 활용하여 데이터 파싱\n",
    "        soup = BeautifulSoup(response.content, \"lxml\")\n",
    "        cap_info = soup.findAll('div', {'class':'tb-center'})\n",
    "\n",
    "        if len(cap_info) == 0 :\n",
    "            print('끝')\n",
    "            break\n",
    "        for cap in cap_info:\n",
    "            name = cap.find('li', {'class':'dsc'}).text\n",
    "            price = cap.find('li', {'class':'price'})\n",
    "            url = cap.find('a').get('href')\n",
    "            #print(\"이름: {}, 가격: {}\".format(name, price))\n",
    "            name_list.append(name)\n",
    "            \n",
    "            if price != None :\n",
    "                price_list.append(price.text)\n",
    "            else :\n",
    "                price_list.append('SOLD OUT')\n",
    "            url_list.append(url)\n",
    "        index = index + 1\n",
    "    except:\n",
    "        print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"이름\": name_list, \"가격\" : price_list, \"url\": url_list})\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
